{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport re\n\nimport cv2\nimport math\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport efficientnet.tfkeras as efn\n\nimport tensorflow as tf\nfrom IPython.display import SVG\nfrom keras.utils import plot_model\nimport tensorflow.keras.layers as L\nfrom keras.utils import model_to_dot\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras.applications import NASNetLarge\n\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.cm as cm\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\ntqdm.pandas()\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nnp.random.seed(0)\ntf.random.set_seed(0)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 10\nSAMPLE_LEN = 100\nIMAGE_PATH = \"../input/plant-pathology-2021-fgvc8/train_images/\"\nTRAIN_PATH = \"../input/plant-pathology-2021-fgvc8/train.csv\"\nSUB_PATH = \"../input/plant-pathology-2021-fgvc8/sample_submission.csv\"\n\nsub = pd.read_csv(SUB_PATH)\ntrain_data = pd.read_csv(TRAIN_PATH)\n# test_data = pd.read_csv(TEST_PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = {}\n\nfor index, row in train_data.iterrows():\n    curLabels = row['labels'].split(' ')\n    if len(curLabels) > 1:\n        continue\n    c = curLabels[0]\n    classes[c] = classes.get(c, 0) + 1\n    \nprint(classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dist_label=train_data['labels'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allLabels = train_data['labels'].unique()\nuniqueLabels = []\n\nfor i in allLabels:\n    curLabels = i.split(' ')\n    for j in curLabels:\n        if j not in uniqueLabels:\n            uniqueLabels.append(j)\n\nfor i in uniqueLabels:\n    train_data[i] = [0] * train_data.shape[0]\n\n\nfor index, row in train_data.iterrows():\n    curLabels = row['labels'].split(' ')\n    for i in uniqueLabels:\n        if i in curLabels:\n            train_data.loc[index, i] = 1\n\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, valid_data = train_test_split(train_data, test_size=0.15, random_state=1010)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape)\nprint(valid_data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_data_generator = ImageDataGenerator(\n    rescale=1./255.0,\n    rotation_range=15,\n    height_shift_range=0.10,\n    width_shift_range=0.10,\n    brightness_range=(0.8, 1.2),\n    zoom_range=0.15,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode=\"nearest\"\n)\n\ncolumns = ['healthy', 'scab', 'frog_eye_leaf_spot', 'complex', 'rust', 'powdery_mildew']\n\ntrain_generator = image_data_generator.flow_from_dataframe(\n    dataframe=train_data,\n    directory=IMAGE_PATH,\n    x_col='image',\n    y_col=columns,\n    color_mode=\"rgb\",\n    class_mode='raw',\n    seed=1010,\n    shuffle=True,\n    target_size=(224, 224),\n    batch_size=16\n)\n\nvalid_generator = image_data_generator.flow_from_dataframe(\n    dataframe=valid_data,\n    directory=IMAGE_PATH,\n    x_col='image',\n    y_col=columns,\n    color_mode=\"rgb\",\n    class_mode='raw',\n    seed=1010,\n    shuffle=True,\n    target_size=(224, 224),\n    batch_size=16\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([efn.EfficientNetB7(input_shape=(224, 224, 3),\n                                                weights='imagenet',\n                                                include_top=False),\n                             L.GlobalAveragePooling2D(),\n                             L.Dense(6, activation='sigmoid')])\n\n\n\nmodel.compile(optimizer='adam',\n              loss = 'binary_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lrfn = build_lrfn()\nSTEPS_SIZE_TRAIN = train_generator.n//train_generator.batch_size\nSTEPS_SIZE_VALID = valid_generator.n//valid_generator.batch_size\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\n\nclass CustomSaver(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % 5 == 0: \n            self.model.save(\"./model_{}.hd5\".format(epoch))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"saver = CustomSaver()\n\nhistory = model.fit_generator(train_generator,\n                    epochs=EPOCHS,\n                    steps_per_epoch=STEPS_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEPS_SIZE_VALID,\n                    callbacks=[lr_schedule, saver],)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndef data_aug(curr_file,number,save_to):\n    data_gen=ImageDataGenerator(rotation_range=8,\n                                width_shift_range=0.1,\n                                height_shift_range=0.1,\n                                shear_range=0.1,\n                                brightness_range=(0.8, 1.2),\n                                horizontal_flip=True,\n                                vertical_flip=True,\n                                fill_mode='nearest'        \n                                )\n    \n    for filename in tqdm(os.listdir(curr_file)):\n        image=cv2.imread(curr_file+filename)\n        image = image.reshape((1,)+image.shape)\n        save_prefix=\"aug_\"+filename[:-4]\n        i=0\n        for batch in data_gen.flow(x=image,batch_size=1,save_to_dir=save_to,save_prefix=save_prefix,\n                                   save_format='jpg'):\n            i+=1\n            if i>number:\n                break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bgr = cv2.imread('../input/plant-pathology-2021-fgvc8/train_images/800113bb65efe69e.jpg')\n\nlab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n\nlab_planes = cv2.split(lab)\n\nclahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))\n\nlab_planes[0] = clahe.apply(lab_planes[0])\n\nlab = cv2.merge(lab_planes)\n\nbgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating an object of CLAHE with tilesize (8,8)\nclahe = cv2.createCLAHE(clipLimit = 2.0, tileGridSize=(8,8))\n\nimg = cv2.imread('../input/plant-pathology-2021-fgvc8/train_images/800113bb65efe69e.jpg')\noriginal_img = img\nresized_img = cv2.resize(original_img, (600, 600))\n# BGR->GRAY\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n#applying CLAHE on Image\ngray_img = clahe.apply(img)\n# Converting back GRAY->RGB\nfinal_img = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)\n# Resizing image to (600, 600)\nresized_final_img = cv2.resize(final_img, (600, 600))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv2.imwrite('./original_image.jpg', original_img)\ncv2.imwrite('./resized_image.jpg', resized_img)\ncv2.imwrite('./final_image.jpg', final_img)\ncv2.imwrite('./resized_final_image.jpg', resized_final_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dist_label=train_data['labels'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allLabels = train_data['labels'].unique()\nuniqueLabels = []\n\nfor i in allLabels:\n    curLabels = i.split(' ')\n    for j in curLabels:\n        if j not in uniqueLabels:\n            uniqueLabels.append(j)\n\nfor i in uniqueLabels:\n    train_data[i] = [0] * train_data.shape[0]\n\n\nallLabs = []\nfor index, row in train_data.iterrows():\n    allLabs.append(row['labels'])\n    curLabels = row['labels'].split(' ')\n    for i in uniqueLabels:\n        if i in curLabels:\n            train_data.loc[index, i] = 1\n\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\nstrategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_path(st):\n    return GCS_DS_PATH + '/train_images/' + st\n\ntrain_paths = train_data.image.apply(format_path).values\n\ntrain_labels = np.float32(train_data.loc[:, 'healthy':'powdery_mildew'].values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_paths, valid_paths, train_labels, valid_labels =\\\ntrain_test_split(train_paths, train_labels, test_size=0.15, random_state=1010)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [600, 600]\n\ndef decode_image(filename, label=None, image_size=(600, 600)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, 0.2)\n    image = tf.image.random_contrast(image, 0.9, 1.1)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\n    \ndef get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation / 180.\n    shear = math.pi * shear / 180.\n    \n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n        \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n    \n    # ZOOM MATRIX\n    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n    \n    # SHIFT MATRIX\n    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n\n\ndef transform(image,label):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n    DIM = IMAGE_SIZE[0]\n    XDIM = DIM%2 #fix for size 331\n    \n    rot = 15. * tf.random.normal([1],dtype='float32')\n    shr = 1.0 * tf.random.normal([1],dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n    h_shift = 10. * tf.random.normal([1],dtype='float32') \n    w_shift = 10. * tf.random.normal([1],dtype='float32') \n      \n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n    d = tf.gather_nd(image,tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,3]),label\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .map(transform, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_paths, valid_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\n# test_dataset = (\n#     tf.data.Dataset\n#     .from_tensor_slices(test_paths)\n#     .map(decode_image, num_parallel_calls=AUTO)\n#     .batch(BATCH_SIZE)\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lrfn = build_lrfn()\nSTEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential([efn.EfficientNetB7(input_shape=(600, 600, 3),\n                                                    weights='imagenet',\n                                                    include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1], activation='sigmoid')])\n\n\n\n    model.compile(optimizer='adam',\n                  loss = 'binary_crossentropy',\n                  metrics=['accuracy'])\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with strategy.scope():\n#     inputs = L.Input((331, 331, 3))\n#     base_model = NASNetLarge(include_top=False, input_shape=(331, 331, 3), weights='imagenet')\n#     x = base_model(inputs)\n#     out1 = L.GlobalMaxPooling2D()(x)\n#     out2 = L.GlobalAveragePooling2D()(x)\n#     out3 = L.Flatten()(x)\n#     out = L.Concatenate(axis=-1)([out1, out2, out3])\n#     out = L.Dropout(0.3)(out)\n#     out = L.Dense(train_labels.shape[1], activation='sigmoid', name=\"3_\")(out)\n#     model = Model(inputs, out)\n#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n#     model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_training_curves(training, validation, yaxis):\n    if yaxis == \"loss\":\n        ylabel = \"Loss\"\n        title = \"Loss vs. Epochs\"\n    else:\n        ylabel = \"Accuracy\"\n        title = \"Accuracy vs. Epochs\"\n        \n    fig = go.Figure()\n        \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=training, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"))\n    \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=validation, marker=dict(color=\"darkorange\"),\n               name=\"Val\"))\n    \n    fig.update_layout(title_text=title, yaxis_title=ylabel, xaxis_title=\"Epochs\", template=\"plotly_white\")\n    fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['acc'], \n    history.history['val_acc'], \n    'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nmodel = keras.models.load_model('./model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TEST_DATA_PATH = '../input/plant-pathology-2021-fgvc8/test_images/'\n\nTEST_DATA_PATH = GCS_DS_PATH + '/test_images/'\n\ndef load_image(filename):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, (331,331))\n    return tf.reshape(image, [-1, 331, 331, 3])\n\n\nlabels = ['healthy', 'scab', 'frog_eye_leaf_spot', 'complex', 'rust', 'powdery_mildew']\n# print(sub.head())\n\nImages = []\nLabels = []\n\nTHRESHOLD = 0.5 \n\ni = 0\nfor img in os.listdir(TEST_DATA_PATH):\n    Images.append(img)\n    img = load_image(TEST_DATA_PATH + img)\n    predictions = model.predict(img)\n    print(predictions)\n    \n    preds = []\n    curPred = []\n    index = 0\n    for pred in predictions[0]:\n        if pred >= THRESHOLD:\n            curPred.append(labels[index])\n        preds.append((index, pred))\n        index += 1\n    \n    preds.sort(key = lambda x: x[1], reverse=True)\n    print(preds)\n    \n    if preds[0][1] < THRESHOLD:\n        curPred = []\n        curPred.append(labels[preds[0][0]])\n    i += 1\n    \n    Labels.append(' '.join(curPred))\n\n\ndict = {'image': Images, 'labels': Labels}\ndf = pd.DataFrame(dict)\ndf.to_csv('submission.csv', index=False)    \n\nsub = pd.read_csv('submission.csv')\nprint(sub.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}